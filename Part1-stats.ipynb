{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#syllabus: https://www.trainingbangalore.in/data-science-with-python-training-in-bangalore.html\n",
    "\n",
    "#python books: https://github.com/oddsun/Free-Python-Books\n",
    "#python and ml books: https://github.com/ab-anand/py-books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Central Tendency\n",
    "Mean\n",
    "Median\n",
    "Mode\n",
    "Skewness\n",
    "Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#central tendency:  one value for representing the whole data \n",
    "\n",
    "#mean  ==> average, (sum/len)\n",
    "## 1,3,-5,6,7,3,5,30,9,2\n",
    "#mean = 6.1\n",
    "#disadvantages: outliers impact is more, advantage: general \n",
    "\n",
    "#median\n",
    "## 1,3,-5,6,7,3,5,30,9,2\n",
    "# -5, 1,2,3,3,5,6,7,9,30\n",
    "\n",
    "#even ===> average of middle values after sorting\n",
    "#odd ===> middle value after sorting\n",
    "\n",
    "#4.0\n",
    "\n",
    "#median will be good if outliers are there.\n",
    "#duplicates\n",
    "\n",
    "#mode frequently occurring value\n",
    "\n",
    "# -5, 1,2,3,3,5,6,7,9,30\n",
    "\n",
    "#3\n",
    "\n",
    "#Difference:\n",
    "\n",
    "#5,0,-5,10,-10\n",
    "\n",
    "#-2,0,2,-1,1\n",
    "\n",
    "#middle value + range / variance\n",
    "\n",
    "\n",
    "#standard deviation\n",
    "#variance\n",
    "\n",
    "#var = std * std \n",
    "\n",
    "#https://www.calculator.net/standard-deviation-calculator.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation variance\n",
    "\n",
    "#population vs sample \n",
    "\n",
    "#sample ===> part of data  ===> N-1  ==> for avoiding errors in approximation or estimation, degree\n",
    "#population the whole data ==> N\n",
    "\n",
    "#maggi 2.6 mg +- 0.05 mg\n",
    "\n",
    "#why n-1\n",
    "#https://towardsdatascience.com/why-sample-variance-is-divided-by-n-1-89821b83ef6d\n",
    "\n",
    "#\n",
    "\n",
    "#train test validation \n",
    "\n",
    "#100 % ===> 80-20 or 70-30 or 85-15 or 50-50 ==> train (80 %) test (20%) split\n",
    "\n",
    "\n",
    "#train ===> 90 %\n",
    "#test ====> 85 % ===> good model\n",
    "\n",
    "#train ===> 90 %\n",
    "#test ====> 65% ===> overfitting\n",
    "\n",
    "#train ===> 60 %\n",
    "#test ====> 45 % 50% ===> underfitting  ==> less than random experiment\n",
    "\n",
    "#if your testing accuracy less ===> overfitting\n",
    "#if training and testing are less ===> underfitting\n",
    "\n",
    "#overfitting and underfitting\n",
    "\n",
    "#regression / classification \n",
    "#regression ==> value , continous ==>\n",
    "#classification ==> yes/no (binary), severity (0/1/2/3/4) ==> discrete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics ===> real data , expolring real data, data interpretation, visualisation, EDA\n",
    "\n",
    "#Inferential statistics ===> Understanding population based on sample\n",
    "\n",
    "    #Qualitative  ==> nominal (no ordering) , ordinal (ordering, priority)  ==> categorical \n",
    "    #Quantitative ===>Discrete (finite, absolute), Continous (infinte, selling price, insurance cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution:\n",
    "\n",
    "#pdf ===> probability distribution/density function\n",
    "\n",
    "#mathemetical equation for your distribution\n",
    "\n",
    "#fair dice ==> equally distributed\n",
    "\n",
    "#Normally distributed  ===> \n",
    "\n",
    "#skewness, curtosis (https://www.excelr.com/skewness-and-kurtosis)\n",
    "# Normal dist formula https://www.thoughtco.com/normal-distribution-bell-curve-formula-3126278\n",
    "#standard normal distribution ==> mu ==0 std ==1\n",
    "#z = x - mu / sigma  https://en.wikipedia.org/wiki/Standard_deviation\n",
    "#1 2 3 rule or 68 95 99.7 rule\n",
    "\n",
    "#avg 174 std =2.5 95 %\n",
    "\n",
    "#174  ==>  171.5 to 176.5 ===> 68.2 %\n",
    "#169 to 179 ===> 95 %\n",
    "#166.5 to 181.5\n",
    "\n",
    "\n",
    "#Binomial Distribution\n",
    "#poisson distribution\n",
    "\n",
    "#corelation ===> pearson / spearman\n",
    "#co variance\n",
    "#\n",
    "\n",
    "#co relation vs covariance\n",
    "#differnt types of distributions with use case\n",
    "#classification and regression in details\n",
    "\n",
    "#covariance: https://byjus.com/covariance-formula/\n",
    "\n",
    "#variance: https://www.sciencebuddies.org/science-fair-projects/science-fair/variance-and-standard-deviation\n",
    "\n",
    "#pearson and spearman correaltion: https://towardsdatascience.com/clearly-explained-pearson-v-s-spearman-correlation-coefficient-ada2f473b8\n",
    "\n",
    "#corelation: relation ship measure\n",
    "\n",
    "#formuala\n",
    "#variance\n",
    "#standard deviation\n",
    "#co variance\n",
    "#correaltion\n",
    "\n",
    "\n",
    "#disrtibution completion\n",
    "#euclidean and manhattan distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#outlier analysis and methods ==> \n",
    "#boxplot\n",
    "#https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51\n",
    "#https://towardsdatascience.com/a-short-journey-of-outlier-detection-bdf143464a92\n",
    "#https://easystats.github.io/performance/reference/check_outliers.html\n",
    "#scatterplot\n",
    "#z score and IQR\n",
    "#cook's distance\n",
    "#https://www.statisticshowto.com/cooks-distance/\n",
    "#123 rule\n",
    "\n",
    "#Underfitting and Overfitting\n",
    "\n",
    "#Overfitting ===> model performs very well in training data, but fail to perform well in test data or outside data\n",
    "#low bias and high variance\n",
    "\n",
    "#Underfitting ==> model performs bad in training, testing also\n",
    "#high bias & high variance\n",
    "\n",
    "#generalised model\n",
    "#low bias and low veriance\n",
    "\n",
    "#bias variance tradeoff\n",
    "#bias ===> training error\n",
    "#variance ===> testing error\n",
    "\n",
    "#https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/\n",
    "#https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690\n",
    "\n",
    "\n",
    "#probabilty & basics\n",
    "#bayes theorem\n",
    "\n",
    "#https://towardsdatascience.com/machine-learning-probability-statistics-f830f8c09326\n",
    "#https://towardsdatascience.com/probability-fundamentals-of-machine-learning-part-1-a156b4703e69\n",
    "#https://towardsdatascience.com/probabiliy-theory-basics-4ef523ae0820\n",
    "\n",
    "\n",
    "#distribution pending\n",
    "\n",
    "#euclidean and manhattan distance\n",
    "\n",
    "#missing value treatment (code)\n",
    "\n",
    "#Error metrics for regression\n",
    "\n",
    "#Error metrics for classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
